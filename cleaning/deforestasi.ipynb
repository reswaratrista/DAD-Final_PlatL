{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33 entries, 0 to 32\n",
      "Data columns (total 29 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   subnational1           33 non-null     object \n",
      " 1   threshold              33 non-null     float64\n",
      " 2   area_ha                33 non-null     float64\n",
      " 3   extent_2000_ha         33 non-null     float64\n",
      " 4   extent_2010_ha         33 non-null     float64\n",
      " 5   gain_2000-2020_ha      33 non-null     float64\n",
      " 6   tc_loss_ha_2001        33 non-null     float64\n",
      " 7   tc_loss_ha_2002        33 non-null     float64\n",
      " 8   tc_loss_ha_2003        33 non-null     float64\n",
      " 9   tc_loss_ha_2004        33 non-null     float64\n",
      " 10  tc_loss_ha_2005        33 non-null     float64\n",
      " 11  tc_loss_ha_2006        33 non-null     float64\n",
      " 12  tc_loss_ha_2007        33 non-null     float64\n",
      " 13  tc_loss_ha_2008        33 non-null     float64\n",
      " 14  tc_loss_ha_2009        33 non-null     float64\n",
      " 15  tc_loss_ha_2010        33 non-null     float64\n",
      " 16  tc_loss_ha_2011        33 non-null     float64\n",
      " 17  tc_loss_ha_2012        33 non-null     float64\n",
      " 18  tc_loss_ha_2013        33 non-null     float64\n",
      " 19  tc_loss_ha_2014        33 non-null     float64\n",
      " 20  tc_loss_ha_2015        33 non-null     float64\n",
      " 21  tc_loss_ha_2016        33 non-null     float64\n",
      " 22  tc_loss_ha_2017        33 non-null     float64\n",
      " 23  tc_loss_ha_2018        33 non-null     float64\n",
      " 24  tc_loss_ha_2019        33 non-null     float64\n",
      " 25  tc_loss_ha_2020        33 non-null     float64\n",
      " 26  tc_loss_ha_2021        33 non-null     float64\n",
      " 27  tc_loss_ha_2022        33 non-null     float64\n",
      " 28  avg_tc_loss_2018-2022  33 non-null     float64\n",
      "dtypes: float64(28), object(1)\n",
      "memory usage: 7.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('cleaned_dataset\\data_deforestasi.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33 entries, 0 to 32\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   subnational1     33 non-null     object \n",
      " 1   tc_loss_ha_2018  33 non-null     float64\n",
      " 2   tc_loss_ha_2019  33 non-null     float64\n",
      " 3   tc_loss_ha_2020  33 non-null     float64\n",
      " 4   tc_loss_ha_2021  33 non-null     float64\n",
      " 5   tc_loss_ha_2022  33 non-null     float64\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 1.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['threshold', 'area_ha', 'extent_2000_ha', 'extent_2010_ha', 'gain_2000-2020_ha', 'tc_loss_ha_2001', 'tc_loss_ha_2002', 'tc_loss_ha_2003', 'tc_loss_ha_2004', 'tc_loss_ha_2005', 'tc_loss_ha_2006', 'tc_loss_ha_2007', 'tc_loss_ha_2008', 'tc_loss_ha_2009', 'tc_loss_ha_2010', 'tc_loss_ha_2011', 'tc_loss_ha_2012', 'tc_loss_ha_2013', 'tc_loss_ha_2014', 'tc_loss_ha_2015', 'tc_loss_ha_2016', 'tc_loss_ha_2017', 'avg_tc_loss_2018-2022'], axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [subnational1, tc_loss_ha_2018, tc_loss_ha_2019, tc_loss_ha_2020, tc_loss_ha_2021, tc_loss_ha_2022]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "data_null = df[df['tc_loss_ha_2022'].isnull()]\n",
    "print(data_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          subnational1  year      tc_loss\n",
      "0                 Aceh  2018  1995.804348\n",
      "1                 Bali  2018    35.513889\n",
      "2               Banten  2018   420.296875\n",
      "3             Bengkulu  2018  2452.187500\n",
      "4        DI Yogyakarta  2018    27.600000\n",
      "..                 ...   ...          ...\n",
      "160  Sulawesi Tenggara  2022  1115.177083\n",
      "161     Sulawesi Utara  2022   182.483333\n",
      "162     Sumatera Barat  2022  1771.056250\n",
      "163   Sumatera Selatan  2022  5791.358333\n",
      "164     Sumatera Utara  2022  1458.823529\n",
      "\n",
      "[165 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df_melt = pd.melt(df, id_vars=['subnational1'], var_name='year', value_name='tc_loss')\n",
    "df_melt['year'] = df_melt['year'].str.extract('(\\d+)').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt.to_csv('tree_cover_loss.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
